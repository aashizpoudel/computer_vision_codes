{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!# Download YOLOv7 code\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "%cd yolov7\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count and generate files\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "gts = []\n",
    "detections = []\n",
    "\n",
    "device = \"cpu\"\n",
    "imgsz=640\n",
    "weights = \"./runs/train/yolov7x/weights/best.pt\"\n",
    "model = attempt_load(weights, map_location=device)\n",
    "# model.eval()\n",
    "stride = int(model.stride.max())  # model stride\n",
    "imgsz = check_img_size(imgsz, s=stride)\n",
    "half = False\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "\n",
    "\n",
    "img_path = \"../train_test_dataset/test/images\" #yolo dataset images location, \n",
    "dataset = LoadImages(img_path,imgsz,stride)\n",
    "\n",
    "conf_thres = 0.5\n",
    "iou_thres = 0.8\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "for path, img, im0s, vid_cap in tqdm(dataset):\n",
    "  img = torch.from_numpy(img).to(device)\n",
    "  img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "  img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "  label_path = path.replace(\"images\",'labels')[:-3]+\"txt\"\n",
    "  with open(label_path,'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "    gts.append({'file':path,'gts':[names[int(line[0])] for line in lines]})\n",
    "  if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)\n",
    "  t1 = time_synchronized()\n",
    "  with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
    "    pred = model(img)[0]\n",
    "  im0 = im0s\n",
    "  s=''\n",
    "  # Apply NMS\n",
    "  pred = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "  detection=[]\n",
    "  for i, det in enumerate(pred):  # detections per image\n",
    "    \n",
    "    gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "    \n",
    "    if len(det):\n",
    "        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "        for c in det[:, -1].unique():\n",
    "            n = (det[:, -1] == c).sum()  # detections per class\n",
    "            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "            detection+= [names[int(c)]]\n",
    "\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            label = f'{names[int(cls)]} {conf:.2f}'\n",
    "            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=2)\n",
    "\n",
    "  # print(s)  \n",
    "  detections.append({'file':path,'detections':detection})\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "def count_class(data,name):\n",
    "  count = 0\n",
    "  for n in data:\n",
    "    if n == name:\n",
    "      count+=1\n",
    "  return count\n",
    "\n",
    "det_df = pd.DataFrame(detections)\n",
    "gt_df = pd.DataFrame(gts)\n",
    "merged_df = pd.merge(gt_df,det_df,on='file')\n",
    "# merged_df.head()\n",
    "for name in names:\n",
    "  merged_df['det_'+name] = merged_df['detections'].apply(lambda x: count_class(x,name) )\n",
    "  merged_df['gt_'+name] = merged_df['gts'].apply(lambda x: count_class(x,name) )\n",
    "merged_df\n",
    "# merged_df.to_csv(\"results.csv\")\n",
    "\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
